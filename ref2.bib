@article{re3,
  author    = {Daniel Gordon and
               Ali Farhadi and
               Dieter Fox},
  title     = {Re3 : Real-Time Recurrent Regression Networks for Object Tracking},
  journal   = {CoRR},
  volume    = {abs/1705.06368},
  year      = {2017},
  url       = {http://arxiv.org/abs/1705.06368},
  archivePrefix = {arXiv},
  eprint    = {1705.06368},
  timestamp = {Mon, 13 Aug 2018 16:48:34 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/GordonFF17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@InProceedings{VOT2014,
  Title                    = {The Visual Object Tracking VOT2014 challenge results},

  Booktitle                = {Proceedings, European Conference on Computer Vision (ECCV) Visual Object Tracking Challenge Workshop},
  Year                     = {2014},

  Address                  = {Zurich, Switzerland},
  Editor                   = {Agapito, Lourdes and Bronstein, Michael M. and Rother, Carsten},
  Month                    = {September},
  Pages                    = {191-217},
  Publisher                = {Springer International Publishing},
  Series                   = {Lecture Notes in Computer Science},
  Volume                   = {8926},

  Abstract                 = {The Visual Object Tracking challenge 2014, VOT2014, aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 38 trackers are presented. The number of tested trackers makes VOT 2014 the largest benchmark on short-term tracking to date. For each participating tracker, a short description is provided in the appendix. Features of the VOT2014 challenge that go beyond its VOT2013 predecessor are introduced: (i) a new VOT2014 dataset with full annotation of targets by rotated bounding boxes and per-frame attribute, (ii) extensions of the VOT2013 evaluation methodology, (iii) a new unit for tracking speed assessment less dependent on the hardware and (iv) the VOT2014 evaluation toolkit that significantly speeds up execution of experiments. The dataset, the evaluation kit as well as the results are publicly available at the challenge website.},
  Day                      = {6},
  Doi                      = {10.1007/978-3-319-16181-5_14},
  Gsid                     = {15633426501004735453},
  ISBN                     = {978-3-319-16180-8},
	gsid = {13408679558583258933,5030672482439802527,11385383912247455161},
  Keywords                 = {Performance evaluation; Short-term single-object trackers; VOT},
  Prestige                 = {international},
  Status                   = {published},
  Timestamp                = {2015.01.01},
  Url                      = {http://personal.ee.surrey.ac.uk/Personal/S.Hadfield/papers/The\%20Visual\%20Object\%20Tracking\%20VOT2014\%20challenge\%20results.pdf}
}


@InProceedings{VOT2016,
  Title                    = {The Visual Object Tracking VOT2016 Challenge Results},
  Booktitle                = {Proceedings, European Conference on Computer Vision (ECCV) workshops},
  Year                     = {2016},
  Month                    = {8} # oct,
 Pages                    = {777--823},
  Abstract                 = {The Visual Object Tracking challenge VOT2016 aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 70 trackers are presented, with a large number of trackers being published at major computer vision conferences and journals in the recent years. The number of tested state-of-the-art trackers makes the VOT 2016 the largest and most challenging benchmark on short-term tracking to date. For each participating tracker, a short description is provided in the Appendix. The VOT2016 goes beyond its predecessors by (i) introducing a new semi-automatic ground truth bounding box annotation methodology and (ii) extending the evaluation system with the no-reset experiment. The dataset, the evaluation kit as well as the results are publicly available at the challenge website (http:// votchallenge. net).},
  Doi                      = {10.1007/978-3-319-48881-3_54},
  Timestamp                = {2016.11.25},
	gsid = {13408679558583258933,5030672482439802527,11385383912247455161},
  Url                      = {http://dx.doi.org/10.1007/978-3-319-48881-3_54}
}



@Article{Hou2017,
author="Hou, Li
and Wan, Wanggen
and Hwang, Jenq-Neng
and Muhammad, Rizwan
and Yang, Mingyang
and Han, Kang",
title="Human tracking over camera networks: a review",
journal="EURASIP Journal on Advances in Signal Processing",
year="2017",
month="Jun",
day="05",
volume="2017",
number="1",
pages="43",
abstract="In recent years, automated human tracking over camera networks is getting essential for video surveillance. The tasks of tracking human over camera networks are not only inherently challenging due to changing human appearance, but also have enormous potentials for a wide range of practical applications, ranging from security surveillance to retail and health care. This review paper surveys the most widely used techniques and recent advances for human tracking over camera networks. Two important functional modules for the human tracking over camera networks are addressed, including human tracking within a camera and human tracking across non-overlapping cameras. The core techniques of human tracking within a camera are discussed based on two aspects, i.e., generative trackers and discriminative trackers. The core techniques of human tracking across non-overlapping cameras are then discussed based on the aspects of human re-identification, camera-link model-based tracking and graph model-based tracking. Our survey aims to address existing problems, challenges, and future research directions based on the analyses of the current progress made toward human tracking techniques over camera networks.",
issn="1687-6180",
doi="10.1186/s13634-017-0482-z",
url="https://doi.org/10.1186/s13634-017-0482-z"
}

@article{DBLP:journals/corr/RedmonF16,
  author    = {Joseph Redmon and
               Ali Farhadi},
  title     = {{YOLO9000:} Better, Faster, Stronger},
  journal   = {CoRR},
  volume    = {abs/1612.08242},
  year      = {2016},
  url       = {http://arxiv.org/abs/1612.08242},
  archivePrefix = {arXiv},
  eprint    = {1612.08242},
  timestamp = {Mon, 13 Aug 2018 16:48:25 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/RedmonF16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}